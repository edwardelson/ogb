{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982f0ad9",
   "metadata": {},
   "source": [
    "This is pulled from https://github.com/snap-stanford/ogb/tree/master/examples/lsc/pcqm4m\n",
    "\n",
    "dependencies:\n",
    "- install rdkit (I used conda) https://www.rdkit.org/docs/Install.html\n",
    "1. conda create -c conda-forge -n my-rdkit-env rdkit\n",
    "2. conda activate my-rdkit-env\n",
    "3. cd [anaconda folder]/bin\n",
    "4. source activate my-rdkit-env\n",
    "\n",
    "- install ogb, torch and pytorch-geometric\n",
    "\n",
    "- run the main-gnn.py code to download the dataset, extract and train (see the readme.md). I could finish extracting because my RAM wasn't enough. If you face the some problem, use this notebook to extract just a handful of the dataset. This code is taken from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecd473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from ogb.lsc import DglPCQM4MDataset, PCQM4MEvaluator\n",
    "\n",
    "import argparse\n",
    "import dgl\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gnn import GNN, DiffPoolGNN, BayesDiffPoolGNN\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "from ogb.utils import smiles2graph\n",
    "from ogb.utils.torch_util import replace_numpy_with_torchtensor\n",
    "from ogb.utils.url import decide_download, download_url, extract_zip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dgl.data.utils import load_graphs, save_graphs, Subset\n",
    "import dgl\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "reg_criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79849beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir log\n",
    "# !mkdir checkpoint\n",
    "# !mkdir test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683d1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python main_gnn.py --gnn gcn --log_dir log --checkpoint_dir checkpoint --save_test_dir test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7d107a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>smiles</th>\n",
       "      <th>homolumogap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cc1ccc(cc1)C1C=c2cnccc2=NC1=O</td>\n",
       "      <td>3.047675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>COc1cc(OC)ccc1C=CN(C(=O)C)C</td>\n",
       "      <td>4.410966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C=CCN(C(=O)C)C=Cc1ccccc1C</td>\n",
       "      <td>4.639541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C=CCN(C(=O)C)C=Cc1ccccc1F</td>\n",
       "      <td>4.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C=CCN(C(=O)C)C=Cc1ccccc1Cl</td>\n",
       "      <td>4.612330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803448</th>\n",
       "      <td>3803448</td>\n",
       "      <td>O=N(=O)c1ccc(c(c1)N(=O)=O)Cl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803449</th>\n",
       "      <td>3803449</td>\n",
       "      <td>NCC(=O)COP(=O)(O)O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803450</th>\n",
       "      <td>3803450</td>\n",
       "      <td>CC(CN)O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803451</th>\n",
       "      <td>3803451</td>\n",
       "      <td>OC1C=CC=C(C1O)C(=O)O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803452</th>\n",
       "      <td>3803452</td>\n",
       "      <td>[O-]C(=O)CC(C[N+](C)(C)C)OC(=O)C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3803453 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             idx                            smiles  homolumogap\n",
       "0              0     Cc1ccc(cc1)C1C=c2cnccc2=NC1=O     3.047675\n",
       "1              1       COc1cc(OC)ccc1C=CN(C(=O)C)C     4.410966\n",
       "2              2         C=CCN(C(=O)C)C=Cc1ccccc1C     4.639541\n",
       "3              3         C=CCN(C(=O)C)C=Cc1ccccc1F     4.492600\n",
       "4              4        C=CCN(C(=O)C)C=Cc1ccccc1Cl     4.612330\n",
       "...          ...                               ...          ...\n",
       "3803448  3803448      O=N(=O)c1ccc(c(c1)N(=O)=O)Cl          NaN\n",
       "3803449  3803449                NCC(=O)COP(=O)(O)O          NaN\n",
       "3803450  3803450                           CC(CN)O          NaN\n",
       "3803451  3803451              OC1C=CC=C(C1O)C(=O)O          NaN\n",
       "3803452  3803452  [O-]C(=O)CC(C[N+](C)(C)C)OC(=O)C          NaN\n",
       "\n",
       "[3803453 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "my folder structure looks like (obtained from running main_gnn)\n",
    "dataset/\n",
    "    pcqm4m_kddcup2021/\n",
    "        mapping/\n",
    "        processed/\n",
    "        raw/\n",
    "            data.csv.gz\n",
    "\"\"\"\n",
    "\n",
    "ROOT = \"dataset/pcqm4m_kddcup2021\"\n",
    "filename = \"{}/{}\".format(ROOT, \"raw/data.csv.gz\")\n",
    "data_df = pd.read_csv(filename)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d237fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Train/Test/Valid split dictionary\n",
    "\"\"\"\n",
    "# INPUT PARAMETERS HERE: SET TRAIN, TEST AND VAL SIZE\n",
    "trainSize = 50000\n",
    "testSize = 10000\n",
    "valSize = 10000\n",
    "\n",
    "# load raw split dict\n",
    "split_dict = torch.load(osp.join(ROOT, 'split_dict.pt'))\n",
    "# load new split dict\n",
    "new_split_dict = split_dict.copy()\n",
    "\n",
    "# sample new split dict\n",
    "new_split_dict[\"train\"] = np.random.choice(new_split_dict[\"train\"], size=trainSize, replace=False)\n",
    "new_split_dict[\"test\"] = np.random.choice(new_split_dict[\"test\"], size=testSize, replace=False)\n",
    "new_split_dict[\"valid\"] = np.random.choice(new_split_dict[\"valid\"], size=valSize, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1c1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train, test and valid indices\n",
    "sampleIndices = np.append(\n",
    "    new_split_dict[\"train\"], [new_split_dict[\"test\"], new_split_dict[\"valid\"]]\n",
    ")\n",
    "\n",
    "# remap indices\n",
    "idMapping = {}\n",
    "for i, index in enumerate(sampleIndices):\n",
    "    idMapping[index] = i\n",
    "    \n",
    "# idMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8582d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eek31\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\eek31\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>smiles</th>\n",
       "      <th>homolumogap</th>\n",
       "      <th>old_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CC(OC(=O)S)CCCC</td>\n",
       "      <td>7.600140</td>\n",
       "      <td>1923243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CC(CN1CCCC1=O)NCC1CCCC1</td>\n",
       "      <td>6.783798</td>\n",
       "      <td>1387256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C=CC[C@H](OC(=O)C=C)CC=O</td>\n",
       "      <td>5.510305</td>\n",
       "      <td>2299827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CC(NCCc1nnc(o1)C(C)(C)C)(C)C</td>\n",
       "      <td>6.081745</td>\n",
       "      <td>1369899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NC(C(=O)O)Cc1n[nH]cc1Cl</td>\n",
       "      <td>6.631415</td>\n",
       "      <td>2007118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>69995</td>\n",
       "      <td>CC(CC1OCCc2c1cc(O)c(c2)O)C</td>\n",
       "      <td>5.542959</td>\n",
       "      <td>3245615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>69996</td>\n",
       "      <td>CC1CO[Si](C1)(C)Cl</td>\n",
       "      <td>8.879075</td>\n",
       "      <td>3047368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>69997</td>\n",
       "      <td>C=CCN=C(COCc1ccccc1)O</td>\n",
       "      <td>5.926640</td>\n",
       "      <td>3343213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>69998</td>\n",
       "      <td>COCCC(=O)CC#N</td>\n",
       "      <td>6.155215</td>\n",
       "      <td>3106791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>69999</td>\n",
       "      <td>COC1=NCC(=NC1)OC</td>\n",
       "      <td>7.050470</td>\n",
       "      <td>3095127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                        smiles  homolumogap  old_idx\n",
       "idx                                                             \n",
       "0          0               CC(OC(=O)S)CCCC     7.600140  1923243\n",
       "1          1       CC(CN1CCCC1=O)NCC1CCCC1     6.783798  1387256\n",
       "2          2      C=CC[C@H](OC(=O)C=C)CC=O     5.510305  2299827\n",
       "3          3  CC(NCCc1nnc(o1)C(C)(C)C)(C)C     6.081745  1369899\n",
       "4          4       NC(C(=O)O)Cc1n[nH]cc1Cl     6.631415  2007118\n",
       "...      ...                           ...          ...      ...\n",
       "69995  69995    CC(CC1OCCc2c1cc(O)c(c2)O)C     5.542959  3245615\n",
       "69996  69996            CC1CO[Si](C1)(C)Cl     8.879075  3047368\n",
       "69997  69997         C=CCN=C(COCc1ccccc1)O     5.926640  3343213\n",
       "69998  69998                 COCCC(=O)CC#N     6.155215  3106791\n",
       "69999  69999              COC1=NCC(=NC1)OC     7.050470  3095127\n",
       "\n",
       "[70000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save New Dataframe based on smaller samples\n",
    "\"\"\"\n",
    "# filter dataframe\n",
    "sampleDF = data_df.iloc[sampleIndices]\n",
    "sampleDF[\"old_idx\"] = sampleDF[\"idx\"]\n",
    "# remap the index\n",
    "sampleDF[\"idx\"] = sampleDF[\"idx\"].apply(lambda x: idMapping[x])\n",
    "sampleDF.index = sampleDF[\"idx\"]\n",
    "\n",
    "# save sample dataframe\n",
    "sampleDF.to_csv(osp.join(ROOT, \"raw\", \"sample_data.csv.gz\"))\n",
    "\n",
    "sampleDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8903af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remap split_dict indices\n",
    "\"\"\"\n",
    "new_split_dict[\"train\"] = np.array([idMapping[x] for x in new_split_dict[\"train\"]])\n",
    "new_split_dict[\"test\"] = np.array([idMapping[x] for x in new_split_dict[\"test\"]])\n",
    "new_split_dict[\"valid\"] = np.array([idMapping[x] for x in new_split_dict[\"valid\"]])\n",
    "\n",
    "torch.save(new_split_dict, osp.join(ROOT, \"sample_split_dict.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8c892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "370e16e3",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbfba40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_dgl(samples):\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return batched_graph, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca694fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.lsc import DglPCQM4MDataset, PCQM4MEvaluator\n",
    "\n",
    "class SampleDglPCQM4MDataset(DglPCQM4MDataset):\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return 'sample_data.csv.gz'\n",
    "\n",
    "    def prepare_graph(self):\n",
    "        processed_dir = osp.join(self.folder, 'processed')\n",
    "        raw_dir = osp.join(self.folder, 'raw')\n",
    "        pre_processed_file_path = osp.join(processed_dir, 'dgl_data_processed')\n",
    "\n",
    "        if osp.exists(pre_processed_file_path):        \n",
    "            # if pre-processed file already exists\n",
    "            self.graphs, label_dict = load_graphs(pre_processed_file_path)\n",
    "            self.labels = label_dict['labels']\n",
    "        else:\n",
    "            # if pre-processed file does not exist\n",
    "            \n",
    "            if not osp.exists(osp.join(raw_dir, 'sample_data.csv.gz')):\n",
    "                # if the raw file does not exist, then download it.\n",
    "                self.download()\n",
    "\n",
    "            data_df = pd.read_csv(osp.join(raw_dir, 'sample_data.csv.gz'))\n",
    "            smiles_list = data_df['smiles']\n",
    "            homolumogap_list = data_df['homolumogap']\n",
    "\n",
    "            print('Converting SMILES strings into graphs...')\n",
    "            self.graphs = []\n",
    "            self.labels = []\n",
    "            for i in tqdm(range(len(smiles_list))):\n",
    "\n",
    "                smiles = smiles_list[i]\n",
    "                homolumogap = homolumogap_list[i]\n",
    "                graph = self.smiles2graph(smiles)\n",
    "                \n",
    "                assert(len(graph['edge_feat']) == graph['edge_index'].shape[1])\n",
    "                assert(len(graph['node_feat']) == graph['num_nodes'])\n",
    "\n",
    "                dgl_graph = dgl.graph((graph['edge_index'][0], graph['edge_index'][1]), num_nodes = graph['num_nodes'])\n",
    "                dgl_graph.edata['feat'] = torch.from_numpy(graph['edge_feat']).to(torch.int64)\n",
    "                dgl_graph.ndata['feat'] = torch.from_numpy(graph['node_feat']).to(torch.int64)\n",
    "\n",
    "                self.graphs.append(dgl_graph)\n",
    "                self.labels.append(homolumogap)\n",
    "\n",
    "            self.labels = torch.tensor(self.labels, dtype=torch.float32)\n",
    "\n",
    "            # double-check prediction target\n",
    "            split_dict = self.get_idx_split()\n",
    "            assert(all([not torch.isnan(self.labels[i]) for i in split_dict['train']]))\n",
    "            assert(all([not torch.isnan(self.labels[i]) for i in split_dict['valid']]))\n",
    "            assert(all([torch.isnan(self.labels[i]) for i in split_dict['test']]))\n",
    "\n",
    "            print('Saving...')\n",
    "            save_graphs(pre_processed_file_path, self.graphs, labels={'labels': self.labels})\n",
    "        \n",
    "    \n",
    "    # just modify the get_idx_split function to call our new filename\n",
    "    def get_idx_split(self):\n",
    "        # NOTE: CHANGED split_dict.pt to sample_split_dict.pt\n",
    "        split_dict = replace_numpy_with_torchtensor(torch.load(osp.join(self.folder, 'sample_split_dict.pt')))\n",
    "        return split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83740713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isSample = True #False #\n",
    "\n",
    "if isSample:\n",
    "    dataset = SampleDglPCQM4MDataset(root = 'dataset/')\n",
    "else:\n",
    "#     !rm dataset/pcqm4m_kddcup2021/processed/geometric_data_processed.pt\n",
    "    dataset = DglPCQM4MDataset(root = 'dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed0ce1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     1,     2,  ..., 49997, 49998, 49999]),\n",
       " tensor([50000, 50001, 50002,  ..., 59997, 59998, 59999]),\n",
       " tensor([60000, 60001, 60002,  ..., 69997, 69998, 69999]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "split_idx[\"train\"] = split_idx[\"train\"].type(torch.LongTensor)\n",
    "split_idx[\"test\"] = split_idx[\"test\"].type(torch.LongTensor)\n",
    "split_idx[\"valid\"] = split_idx[\"valid\"].type(torch.LongTensor)\n",
    "\n",
    "split_idx[\"train\"], split_idx[\"test\"], split_idx[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b668ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = PCQM4MEvaluator()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7dbea499",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "GET ARGUMENTS FROM EXAMPLE\n",
    "\"\"\"\n",
    "\n",
    "python main_gnn.py --gnn gcn --log_dir $LOG_DIR --checkpoint_dir $CHECKPOINT_DIR --save_test_dir $TEST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49aefc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args from main_gnn CLI\n",
    "class Argument(object):\n",
    "    name = \"args\"\n",
    "    \n",
    "args = Argument()\n",
    "args.batch_size = 256\n",
    "args.num_workers = 0\n",
    "args.num_layers = 5\n",
    "args.emb_dim = 600\n",
    "args.drop_ratio = 0\n",
    "args.graph_pooling = \"sum\"\n",
    "args.checkpoint_dir = \"checkpoint\"\n",
    "args.device = 0\n",
    "args.log_dir = \"models/gin-virtual/log\"\n",
    "args.checkpoint_dir = \"models/gin-virtual/checkpoint\"\n",
    "args.train_subset = False\n",
    "args.epochs = 1\n",
    "args.save_test_dir = \"models/gin-virtual/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c96ed39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d2de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.batch_size, shuffle=True, num_workers = args.num_workers, collate_fn=collate_dgl)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers, collate_fn=collate_dgl)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers, collate_fn=collate_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff3af0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_params = {\n",
    "    'num_layers': args.num_layers,\n",
    "    'emb_dim': args.emb_dim,\n",
    "    'drop_ratio': args.drop_ratio,\n",
    "    'graph_pooling': args.graph_pooling\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36108172",
   "metadata": {},
   "source": [
    "## default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105bfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gnn import GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d09b31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GNN(gnn_type='gin', virtual_node=True, **shared_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2757f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if checkpoint exist -> load model\n",
    "# checkpointFile = os.path.join(args.checkpoint_dir, 'checkpoint.pt')\n",
    "# if os.path.exists(checkpointFile):\n",
    "#     # load weights\n",
    "#     print(\"Loading existing weights from {}\".format(checkpointFile))\n",
    "#     checkpointData = torch.load(checkpointFile)\n",
    "#     model.load_state_dict(checkpointData[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b293c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from main import train, eval, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2af52bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f'#Params: {num_params}')\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# if args.log_dir is not '':\n",
    "#     writer = SummaryWriter(log_dir=args.log_dir)\n",
    "\n",
    "# best_valid_mae = 1000\n",
    "\n",
    "# if args.train_subset:\n",
    "#     scheduler = StepLR(optimizer, step_size=300, gamma=0.25)\n",
    "#     args.epochs = 1000\n",
    "# else:\n",
    "#     scheduler = StepLR(optimizer, step_size=30, gamma=0.25)\n",
    "\n",
    "# for epoch in range(1, args.epochs + 1):\n",
    "#     print(\"=====Epoch {}\".format(epoch))\n",
    "#     print('Training...')\n",
    "#     train_mae = train(model, device, train_loader, optimizer)\n",
    "\n",
    "#     print('Evaluating...')\n",
    "#     valid_mae = eval(model, device, valid_loader, evaluator)\n",
    "\n",
    "#     print({'Train': train_mae, 'Validation': valid_mae})\n",
    "\n",
    "#     if args.log_dir is not '':\n",
    "#         writer.add_scalar('valid/mae', valid_mae, epoch)\n",
    "#         writer.add_scalar('train/mae', train_mae, epoch)\n",
    "\n",
    "#     if valid_mae < best_valid_mae:\n",
    "#         best_valid_mae = valid_mae\n",
    "#         if args.checkpoint_dir is not '':\n",
    "#             print('Saving checkpoint...')\n",
    "#             checkpoint = {'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
    "#                           'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                           'scheduler_state_dict': scheduler.state_dict(), 'best_val_mae': best_valid_mae,\n",
    "#                           'num_params': num_params}\n",
    "#             torch.save(checkpoint, os.path.join(args.checkpoint_dir, 'checkpoint.pt'))\n",
    "\n",
    "#         if args.save_test_dir is not '':\n",
    "#             print('Predicting on test data...')\n",
    "#             y_pred = test(model, device, test_loader)\n",
    "# #             print('Saving test submission file...')\n",
    "# #             evaluator.save_test_submission({'y_pred': y_pred}, args.save_test_dir)\n",
    "\n",
    "#     scheduler.step()\n",
    "\n",
    "#     print(f'Best validation MAE so far: {best_valid_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceae5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26cece67",
   "metadata": {},
   "source": [
    "## DiffPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d14e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import dgl\n",
    "\n",
    "from model.dgl_layers import GraphSage, GraphSageLayer, DiffPoolBatchedGraphLayer\n",
    "from model.tensorized_layers import *\n",
    "from model.model_utils import batch2tensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b8caae-538e-4fb8-bc7c-536dbbf93891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "from model.dgl_layers.aggregator import MaxPoolAggregator, MeanAggregator, LSTMAggregator\n",
    "from model.dgl_layers.bundler import Bundler\n",
    "from model.model_utils import masked_softmax\n",
    "from model.loss import EntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58192313-210b-48fd-a89d-9eb83f593cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.tensorized_layers import BatchedGraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d72fda-fbd6-44d9-8779-5884d85ddf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchbnn as bnn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b03b78b0-e853-4af0-b926-7752e4720fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bundler(nn.Module):\n",
    "    \"\"\"\n",
    "    Bundler, which will be the node_apply function in DGL paradigm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feats, out_feats, activation, dropout, bias=True):\n",
    "        super(Bundler, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(in_feats * 2, out_feats, bias)\n",
    "        self.activation = activation\n",
    "\n",
    "        nn.init.xavier_uniform_(self.linear.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def concat(self, h, aggre_result):\n",
    "        bundle = torch.cat((h, aggre_result), 1)\n",
    "        bundle = self.linear(bundle)\n",
    "        return bundle\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = node.data['h']\n",
    "        c = node.data['c']\n",
    "        bundle = self.concat(h, c)\n",
    "        bundle = F.normalize(bundle, p=2, dim=1)\n",
    "        if self.activation:\n",
    "            bundle = self.activation(bundle)\n",
    "        return {\"h\": bundle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82af459d-8789-4f72-98f5-bcf2bbc87577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSageLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSage layer in Inductive learning paper by hamilton\n",
    "    Here, graphsage layer is a reduced function in DGL framework\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feats, out_feats, activation, dropout,\n",
    "                 aggregator_type, bn=False, bias=True):\n",
    "        super(GraphSageLayer, self).__init__()\n",
    "        self.use_bn = bn\n",
    "        self.bundler = Bundler(in_feats, out_feats, activation, dropout,\n",
    "                               bias=bias)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        if aggregator_type == \"maxpool\":\n",
    "            self.aggregator = MaxPoolAggregator(in_feats, in_feats,\n",
    "                                                activation, bias)\n",
    "        elif aggregator_type == \"lstm\":\n",
    "            self.aggregator = LSTMAggregator(in_feats, in_feats)\n",
    "        else:\n",
    "            self.aggregator = MeanAggregator()\n",
    "\n",
    "    # edge_attr not used\n",
    "    def forward(self, g, h):\n",
    "        h = self.dropout(h)\n",
    "        g.ndata['h'] = h\n",
    "        if self.use_bn and not hasattr(self, 'bn'):\n",
    "            device = h.device\n",
    "            self.bn = nn.BatchNorm1d(h.size()[1]).to(device)\n",
    "        g.update_all(fn.copy_src(src='h', out='m'), self.aggregator,\n",
    "                     self.bundler)\n",
    "        if self.use_bn:\n",
    "            h = self.bn(h)\n",
    "        h = g.ndata.pop('h')\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd4ac9eb-648b-4b23-8553-48db67fc2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "declass DiffPoolBatchedGraphLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, assign_dim, output_feat_dim,\n",
    "                 activation, dropout, aggregator_type, link_pred):\n",
    "        super(DiffPoolBatchedGraphLayer, self).__init__()\n",
    "        self.embedding_dim = input_dim\n",
    "        self.assign_dim = assign_dim\n",
    "        self.hidden_dim = output_feat_dim\n",
    "        self.link_pred = link_pred\n",
    "        \n",
    "        self.feat_gc = GraphSageLayer(\n",
    "            input_dim,\n",
    "            output_feat_dim,\n",
    "            activation,\n",
    "            dropout,\n",
    "            aggregator_type)\n",
    "\n",
    "        self.pool_gc = GraphSageLayer(\n",
    "            input_dim,\n",
    "            assign_dim,\n",
    "            activation,\n",
    "            dropout,\n",
    "            aggregator_type)\n",
    "        \n",
    "        self.reg_loss = nn.ModuleList([])\n",
    "        self.loss_log = {}\n",
    "        self.reg_loss.append(EntropyLoss())\n",
    "\n",
    "    def forward(self, g, h):\n",
    "#         print(\"DiffPoolBatchedGraphLayer forward\")de\n",
    "        feat = self.feat_gc(g, h)  # size = (sum_N, F_out), sum_N is num of nodes in this batch\n",
    "#         print(feat.shape)\n",
    "        device = feat.device\n",
    "        assign_tensor = self.pool_gc(g, h)  # size = (sum_N, N_a), N_a is num of nodes in pooled graph.\n",
    "        assign_tensor = F.softmax(assign_tensor, dim=1)\n",
    "        assign_tensor = torch.split(assign_tensor, g.batch_num_nodes().tolist())\n",
    "        assign_tensor = torch.block_diag(*assign_tensor)  # size = (sum_N, batch_size * N_a)\n",
    "\n",
    "        h = torch.matmul(torch.t(assign_tensor), feat)\n",
    "        adj = g.adjacency_matrix(transpose=False, ctx=device)\n",
    "        adj_new = torch.sparse.mm(adj, assign_tensor)\n",
    "        adj_new = torch.mm(torch.t(assign_tensor), adj_new)\n",
    "\n",
    "        if self.link_pred:\n",
    "            current_lp_loss = torch.norm(adj.to_dense() -\n",
    "                                         torch.mm(assign_tensor, torch.t(assign_tensor))) / np.power(g.number_of_nodes(), 2)\n",
    "            self.loss_log['LinkPredLoss'] = current_lp_loss\n",
    "\n",
    "        for loss_layer in self.reg_loss:\n",
    "            loss_name = str(type(loss_layer).__name__)\n",
    "            self.loss_log[loss_name] = loss_layer(adj, adj_new, assign_tensor)\n",
    "\n",
    "        return adj_new, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d048def-6ce9-4011-8cd5-a6f185520b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=embedding_dim, out_features=100),\n",
    "\n",
    "class BayesBundler(Bundler):\n",
    "    \"\"\"\n",
    "    BayesBundler, which will be the node_apply function in DGL paradigm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feats, out_feats, activation, dropout, bias=True):\n",
    "        super(BayesBundler, self).__init__(in_feats, out_feats, activation, dropout, bias)\n",
    "        self.linear = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=in_feats * 2, out_features=out_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4566e14-7522-4fee-9464-afff9937c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesGraphSageLayer(GraphSageLayer):\n",
    "    \"\"\"\n",
    "    BayesGraphSage layer in Inductive learning paper by hamilton\n",
    "    Here, graphsage layer is a reduced function in DGL framework\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feats, out_feats, activation, dropout,\n",
    "                 aggregator_type, bn=False, bias=True):\n",
    "        super(BayesGraphSageLayer, self).__init__(in_feats, out_feats, activation, dropout,\n",
    "                 aggregator_type, bn, bias)\n",
    "        self.bundler = BayesBundler(in_feats, out_feats, activation, dropout,\n",
    "                               bias=bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "047c270a-aad4-44ec-bf29-b6b15e5511f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesDiffPoolBatchedGraphLayer(DiffPoolBatchedGraphLayer):\n",
    "\n",
    "    def __init__(self, input_dim, assign_dim, output_feat_dim,\n",
    "                 activation, dropout, aggregator_type, link_pred):\n",
    "        super(BayesDiffPoolBatchedGraphLayer, self).__init__(input_dim, assign_dim, output_feat_dim,\n",
    "                 activation, dropout, aggregator_type, link_pred)\n",
    "        \n",
    "        self.feat_gc = BayesGraphSageLayer(\n",
    "            input_dim,\n",
    "            output_feat_dim,\n",
    "            activation,\n",
    "            dropout,\n",
    "            aggregator_type)\n",
    "\n",
    "        self.pool_gc = BayesGraphSageLayer(\n",
    "            input_dim,\n",
    "            assign_dim,\n",
    "            activation,\n",
    "            dropout,\n",
    "            aggregator_type)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddf7ef9f-2700-4158-ac8f-51f48bbf1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesBatchedGraphSAGE(BatchedGraphSAGE):\n",
    "    def __init__(self, infeat, outfeat, use_bn=True,\n",
    "                 mean=False, add_self=False):\n",
    "        super().__init__(infeat, outfeat, use_bn,\n",
    "                 mean, add_self)\n",
    "        self.W = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=infeat, out_features=outfeat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb509b2f-7bb6-4ed0-affc-c353a05d3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dgl.nn.pytorch import SumPooling, AvgPooling, MaxPooling, GlobalAttentionPooling, Set2Set\n",
    "\n",
    "from conv import GNN_node, GNN_node_Virtualnode\n",
    "\n",
    "from gnn import GNN\n",
    "\n",
    "class DiffPoolGNN(GNN):\n",
    "    def __init__(self, num_tasks = 1, num_layers = 5, emb_dim = 300, gnn_type = 'gin',\n",
    "                 virtual_node = True, residual = False, drop_ratio = 0, JK = \"last\",\n",
    "                 graph_pooling = \"sum\"):\n",
    "        super(DiffPoolGNN, self).__init__(num_tasks, num_layers, emb_dim, gnn_type,\n",
    "                 virtual_node, residual, drop_ratio, JK, graph_pooling)\n",
    "        \n",
    "        # 2x number of outputs\n",
    "        self.graph_pred_linear = nn.Linear(2*self.emb_dim, self.num_tasks)\n",
    "#         self.graph_pred_linear = nn.Linear(self.emb_dim, self.num_tasks)\n",
    "\n",
    "        self.first_diffpool_layer = DiffPoolBatchedGraphLayer(\n",
    "            input_dim=600, # graph embedding dimension\n",
    "            assign_dim=5, # group to 10\n",
    "            output_feat_dim=600,\n",
    "            activation=F.relu,\n",
    "            dropout=0.0,\n",
    "            aggregator_type=\"meanpool\",\n",
    "            link_pred=False\n",
    "        ).to(device)\n",
    "\n",
    "        self.gc_after_pool = BatchedGraphSAGE(600, 600).to(device)\n",
    "\n",
    "    def forward(self, g, x, edge_attr):\n",
    "        # 1. GCN: 3628x9 -> 3628x600\n",
    "        g.ndata['h'] = x\n",
    "        h_node = self.gnn_node(g, x, edge_attr)\n",
    "#         print(h_node.shape)\n",
    "\n",
    "        # 2. Graph Pooling 256x600\n",
    "        h_graph_1 = self.pool(g, h_node)\n",
    "#         print(h_graph.shape)\n",
    "        \n",
    "        # 3. DiffPool: (1280x1280), (1280x600)\n",
    "        adj, h_node = self.first_diffpool_layer(g, h_node)\n",
    "#         print(adj.shape, h_node.shape)\n",
    "        \n",
    "        # 3b. split to batches\n",
    "        node_per_pool_graph = int(adj.size()[0] / len(g.batch_num_nodes()))\n",
    "        h_node, adj = batch2tensor(adj, h_node, node_per_pool_graph)\n",
    "#         print(adj.shape, h_node.shape)\n",
    "\n",
    "        # 4. GCN:\n",
    "        h_node = self.gcn_forward_tensorized(h_node, adj, [self.gc_after_pool], True)\n",
    "#         print(h_node.shape)\n",
    "\n",
    "        # 5. Graph Pooling 256x600\n",
    "        h_graph_2 = torch.sum(h_node, dim=1)\n",
    "#         print(\"h_graph_2\", h_graph_2.shape)\n",
    "\n",
    "        # 6. Last Layer; Combine Graph Embeddings\n",
    "#         print(h_graph_1.shape, h_graph_2.shape)\n",
    "        h_graph = torch.cat([h_graph_1, h_graph_2], dim=1)\n",
    "#         h_graph = h_graph_1\n",
    "\n",
    "        output = self.graph_pred_linear(h_graph)\n",
    "#         print(\"output\", output.shape)\n",
    "\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            return torch.clamp(output, min=0, max=50)\n",
    "\n",
    "    def gcn_forward_tensorized(self, h, adj, gc_layers, cat=False):\n",
    "        block_readout = []\n",
    "        for gc_layer in gc_layers:\n",
    "            h = gc_layer(h, adj)\n",
    "            block_readout.append(h)\n",
    "        if cat:\n",
    "            block = torch.cat(block_readout, dim=2)  # N x F, F = F1 + F2 + ...\n",
    "        else:\n",
    "            block = h\n",
    "        return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6329a7e2-bc4a-4e71-ad41-434bc6deddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesDiffPoolGNN(DiffPoolGNN):\n",
    "    def __init__(self, num_tasks = 1, num_layers = 5, emb_dim = 300, gnn_type = 'gin',\n",
    "                 virtual_node = True, residual = False, drop_ratio = 0, JK = \"last\",\n",
    "                 graph_pooling = \"sum\"):\n",
    "        super(BayesDiffPoolGNN, self).__init__(num_tasks, num_layers, emb_dim, gnn_type,\n",
    "                 virtual_node, residual, drop_ratio, JK, graph_pooling)\n",
    "        \n",
    "        # 2x number of outputs\n",
    "        self.graph_pred_linear = torch.nn.Sequential(\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2*self.emb_dim, out_features=100),\n",
    "            torch.nn.ReLU(),\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=100, out_features=100),\n",
    "            torch.nn.ReLU(),\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=100, out_features=100),\n",
    "            torch.nn.ReLU(),\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=100, out_features=self.num_tasks),\n",
    "        )\n",
    "        \n",
    "        self.first_diffpool_layer = BayesDiffPoolBatchedGraphLayer(\n",
    "            input_dim=600, # graph embedding dimension\n",
    "            assign_dim=5, # group to 10\n",
    "            output_feat_dim=600,\n",
    "            activation=F.relu,\n",
    "            dropout=0.0,\n",
    "            aggregator_type=\"meanpool\",\n",
    "            link_pred=False\n",
    "        ).to(device)\n",
    "\n",
    "        self.gc_after_pool = BayesBatchedGraphSAGE(600, 600).to(device)\n",
    "\n",
    "        # KL-divergence loss for Bayesian Neural Network\n",
    "        self.kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "        self.kl_weight = 1 # 0.01\n",
    "\n",
    "    def get_kl_loss(self):\n",
    "        kl_losses = self.kl_loss(self.graph_pred_linear) + self.kl_loss(self.first_diffpool_layer) + self.kl_loss(self.gc_after_pool)\n",
    "        return self.kl_weight * kl_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e151b4ec-82f3-4d74-99a9-022dc7bad5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "import gnn\n",
    "reload(gnn)\n",
    "from gnn import GNN, DiffPoolGNN, BayesDiffPoolGNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65311b09-fa70-4c8f-a841-c9e98b2a2d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gnn.BayesDiffPoolGNN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = DiffPoolGNN(gnn_type='gin', virtual_node=True, **shared_params).to(device)\n",
    "# type(model)\n",
    "\n",
    "model = BayesDiffPoolGNN(gnn_type='gin', virtual_node=True, **shared_params).to(device)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91df3162-8cd2-48db-a056-18e23dc7c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ca08093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                 | 13/196 [00:07<01:45,  1.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f81217185fb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# TODO: add loss from bayeslinear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_mae = train(model, device, train_loader, optimizer)\n",
    "\n",
    "loader = train_loader\n",
    "\n",
    "# train\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    loss_accum = 0\n",
    "    for step, (bg, labels) in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        bg = bg.to(device)\n",
    "        x = bg.ndata.pop('feat').to(device)\n",
    "        edge_attr = bg.edata.pop('feat').to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model(bg, x, edge_attr).view(-1,)\n",
    "        optimizer.zero_grad()\n",
    "        loss = reg_criterion(pred, labels)\n",
    "              \n",
    "#         if gnn_name == 'gin-virtual-bnn':\n",
    "        kl_loss = model.get_kl_loss()[0]\n",
    "        loss += kl_loss\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # TODO: add loss from bayeslinear\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "    print(loss_accum / (step + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ac9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0d48aa3f-c8dd-470f-b880-8cb27fa12c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BayesDiffPoolBatchedGraphLayer' from 'model.dgl_layers' (C:\\Users\\eek31\\Documents\\GitHub\\ogb\\examples\\lsc\\pcqm4m-dgl\\model\\dgl_layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-f424a8ebe8f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiffPoolGNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBayesDiffPoolGNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"spec not found for the module {name!r}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;31m# The module may have replaced itself in sys.modules!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_exec\u001b[1;34m(spec, module)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ogb\\examples\\lsc\\pcqm4m-dgl\\gnn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mhierarchical\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \"\"\"\n\u001b[1;32m---> 80\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdgl_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGraphSage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGraphSageLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiffPoolBatchedGraphLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBayesDiffPoolBatchedGraphLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorized_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchedGraphSAGE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBayesBatchedGraphSAGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbatch2tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BayesDiffPoolBatchedGraphLayer' from 'model.dgl_layers' (C:\\Users\\eek31\\Documents\\GitHub\\ogb\\examples\\lsc\\pcqm4m-dgl\\model\\dgl_layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "# from importlib import reload \n",
    "# import gnn\n",
    "# reload(gnn)\n",
    "# from gnn import GNN, DiffPoolGNN, BayesDiffPoolGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59db58-af58-49ec-9d22-85565079b7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3e16e-2058-4619-9e87-225f266d62e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b83554-6abf-4ef9-9972-d4d6b63cfc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605d12c-e1d5-478e-9aa4-16a59c918e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f541f1a2-4ceb-4d72-9e1e-fedb33511418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd2dc4-ef5a-4a8a-a7cf-441f9b72463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a09e3-e312-4b61-8b2b-6f5447dc1e24",
   "metadata": {},
   "source": [
    "## interpret localpooling node mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9e1aa-f267-48b6-b4cb-7dcee71996f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    g, x, edge_attr = bg, x, edge_attr\n",
    "    g.ndata['h'] = x\n",
    "    h_node = model.gnn_node(g, x, edge_attr)\n",
    "#         print(h_node.shape)\n",
    "\n",
    "    # 3. DiffPool: (1280x1280), (1280x600)\n",
    "#     adj, h_node = first_diffpool_layer(g, h_node)    \n",
    "    g, h = g, h_node\n",
    "#         print(\"DiffPoolBatchedGraphLayer forward\")\n",
    "    feat = first_diffpool_layer.feat_gc(g, h)  # size = (sum_N, F_out), sum_N is num of nodes in this batch\n",
    "#         print(feat.shape)\n",
    "    device = feat.device\n",
    "    assign_tensor = first_diffpool_layer.pool_gc(g, h)  # size = (sum_N, N_a), N_a is num of nodes in pooled graph.\n",
    "    assign_tensor = F.softmax(assign_tensor, dim=1)\n",
    "    assign_tensor = torch.split(assign_tensor, g.batch_num_nodes().tolist())\n",
    "#     assign_tensor = torch.block_diag(*assign_tensor)  # size = (sum_N, batch_size * N_a)\n",
    "\n",
    "    # fix to 5 nodes\n",
    "#     node_per_pool_graph = int(adj.size()[0] / len(g.batch_num_nodes()))\n",
    "#     h_node, adj = batch2tensor(adj, h_node, node_per_pool_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab38b8f-7b52-463b-99a5-439acdddf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 106\n",
    "g.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d879f9a-7026-4679-90e9-6bdf92e05861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ad2ec-dd2f-496d-b43f-a9b15aab3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbatchG = dgl.unbatch(g)\n",
    "\n",
    "for i in range(len(assign_tensor)):\n",
    "    print(i)\n",
    "    mapping = assign_tensor[i].cpu().numpy()\n",
    "    plt.imshow(mapping, aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "#     i = 106\n",
    "#     A = unbatchG[i].adj(scipy_fmt='coo').toarray()\n",
    "#     plt.imshow(A)\n",
    "#     plt.show()\n",
    "\n",
    "    G = unbatchG[i].cpu().to_networkx()\n",
    "#     simpleG = nx.Graph()\n",
    "#     simpleG.add_edges_from(list(G.edges()))\n",
    "    \n",
    "    maxColor = mapping.argmax(axis=1)\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    posArr = np.array([x for _, x in pos.items()])\n",
    "    maxColor = mapping.argmax(axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for edge in G.edges():\n",
    "    #     print(edge)\n",
    "        ax.plot([posArr[edge[0]][0], posArr[edge[1]][0]], [posArr[edge[0]][1], posArr[edge[1]][1]], 'b-')\n",
    "\n",
    "    ax.scatter(posArr[:, 0], posArr[:, 1], c=maxColor, s=100)\n",
    "    for txt, ij in pos.items():\n",
    "        ax.annotate(txt, (ij[0], ij[1]))\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c210320-aad7-42d4-a66d-126df49a3d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc236ea-533e-46fc-80b1-a534ab87df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in assign_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cd0a8-b699-4440-8a6a-e137dc492090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5972c7c-04d0-48f8-92e6-55c5c5f901cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj.shape, h_node.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8f5c2-24ed-430d-8c80-be73818d0c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
