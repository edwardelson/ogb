{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a374de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from gnn import GNN\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317a9c0",
   "metadata": {},
   "source": [
    "### hard-coded arguments\n",
    "\n",
    "explain GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722689f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args from main_gnn CLI\n",
    "class Argument(object):\n",
    "    name = \"args\"\n",
    "    \n",
    "args = Argument()\n",
    "args.batch_size = 256\n",
    "args.num_workers = 0\n",
    "args.num_layers = 5\n",
    "args.emb_dim = 600\n",
    "args.drop_ratio = 0\n",
    "args.graph_pooling = \"sum\"\n",
    "args.checkpoint_dir = \"models/gin-virtual/checkpoint\"\n",
    "args.device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe227019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773c9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_params = {\n",
    "    'num_layers': args.num_layers,\n",
    "    'emb_dim': args.emb_dim,\n",
    "    'drop_ratio': args.drop_ratio,\n",
    "    'graph_pooling': args.graph_pooling\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8d831",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a0b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn import GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a1b8d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'best_val_mae', 'num_params'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LOAD Checkpoint data\n",
    "\"\"\"\n",
    "checkpoint = torch.load(os.path.join(args.checkpoint_dir, 'checkpoint.pt'))\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81d09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_name = \"gin-virtual\"\n",
    "gnn_type = \"gin\"\n",
    "virtual_node = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c278acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gnn.GNN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNN(gnn_type = gnn_type, virtual_node = virtual_node, **shared_params).to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.state_dict()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e106921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=300, gamma=0.25)\n",
    "reg_criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb203ed",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db77a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing OGB-LSC\n",
    "from ogb.lsc import PygPCQM4MDataset, PCQM4MEvaluator\n",
    "\n",
    "dataset = PygPCQM4MDataset(root = 'dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a484d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([      0,       1,       2,  ..., 3045357, 3045358, 3045359]),\n",
       " tensor([3426030, 3426031, 3426032,  ..., 3803450, 3803451, 3803452]),\n",
       " tensor([3045360, 3045361, 3045362,  ..., 3426027, 3426028, 3426029]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "split_idx[\"train\"], split_idx[\"test\"], split_idx[\"valid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54975c5-e3a0-4517-87ba-c049dda14a50",
   "metadata": {},
   "source": [
    "### triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f608b2ea-ea51-47d3-bae7-5565ef90a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define triplet loss\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import global_add_pool\n",
    "\n",
    "class TripletLossRegression(nn.Module):\n",
    "    \"\"\"\n",
    "        anchor, positive, negative are node-level embeddings of a GNN before they are sent to a pooling layer,\n",
    "        and hence are expected to be matrices.\n",
    "        anchor_gt, positive_gt, and negative_gt are ground truth tensors that correspond to the ground-truth\n",
    "        values of the anchor, positive, and negative respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin: float = 0.0, eps=1e-6):\n",
    "        super(TripletLossRegression, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, anchor: Tensor, negative: Tensor, positive: Tensor,\n",
    "                anchor_gt: Tensor, negative_gt: Tensor, positive_gt: Tensor) -> Tensor:\n",
    "\n",
    "        # get distance\n",
    "        pos_distance = torch.linalg.norm(positive - anchor, dim=1)\n",
    "        negative_distance = torch.linalg.norm(negative - anchor, dim=1)\n",
    "\n",
    "        coeff = torch.div(torch.abs(negative_gt - anchor_gt) , (torch.abs(positive_gt - anchor_gt) + self.eps))\n",
    "        loss = F.relu((pos_distance - coeff * negative_distance) + self.margin)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eceabe50-2591-4979-abc5-801b94df4f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2888ee77fc8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "get embedding\n",
    "\"\"\"\n",
    "model_activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        model_activation[name] = output\n",
    "    return hook\n",
    "\n",
    "model.gnn_node.register_forward_hook(get_activation('gnn_node'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39f0a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.data.dataloader.DataLoader at 0x288fc3dcf48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "load training dataset\n",
    "\"\"\"\n",
    "\n",
    "name = \"valid\"\n",
    "\n",
    "train_loader = DataLoader(dataset[split_idx[name]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f863153b-5ce4-4e7f-801c-726811b3be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load triplet dataset\n",
    "\"\"\"\n",
    "anchor_loader = DataLoader(dataset[split_idx[name]], batch_size=args.batch_size, shuffle=True, num_workers = args.num_workers)\n",
    "positive_loader = DataLoader(dataset[split_idx[name]], batch_size=args.batch_size, shuffle=True, num_workers = args.num_workers)\n",
    "negative_loader = DataLoader(dataset[split_idx[name]], batch_size=args.batch_size, shuffle=True, num_workers = args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124ff9b-7da3-4f4f-9966-bfe34426fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dynamic triplet dataset based on error\n",
    "\"\"\"\n",
    "\n",
    "# 1. get losses for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22cd3588-6dd5-4650-9ab8-9bf5df1b66df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|███████████████████████████████████████████████████████████████████| 1487/1487 [12:21<00:00,  2.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9765289135041779"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def triplet_loss_train(model, device, anchor_loader, negative_loader, positive_loader, optimizer, gnn_name):\n",
    "model.train()\n",
    "loss_accum = 0\n",
    "triplet_loss_criterion = TripletLossRegression()\n",
    "\n",
    "for step, (anchor_batch, negative_batch, positive_batch) in \\\n",
    "        enumerate(zip(tqdm(anchor_loader, desc=\"Iteration\"), negative_loader, positive_loader)):\n",
    "    anchor_batch = anchor_batch.to(device)\n",
    "    pred_anchor = model(anchor_batch).view(-1,)\n",
    "    anchor_embed = model_activation['gnn_node']\n",
    "    anchor_embed = model.pool(anchor_embed, anchor_batch.batch)\n",
    "\n",
    "    negative_batch = negative_batch.to(device)\n",
    "    pred_neg = model(negative_batch).view(-1,)\n",
    "    neg_embed = model_activation['gnn_node']\n",
    "    neg_embed = model.pool(neg_embed, negative_batch.batch)\n",
    "\n",
    "    positive_batch = positive_batch.to(device)\n",
    "    pred_pos= model(positive_batch).view(-1,)\n",
    "    pos_embed = model_activation['gnn_node']\n",
    "    pos_embed = model.pool(pos_embed, positive_batch.batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # 1. MAE loss\n",
    "    mae_loss = reg_criterion(pred_anchor, anchor_batch.y)\n",
    "    \n",
    "    # 2. Triplet Loss\n",
    "    tll_loss = triplet_loss_criterion(anchor_embed, neg_embed, pos_embed,\n",
    "                                      anchor_batch.y, negative_batch.y, positive_batch.y)\n",
    "    loss = mae_loss + tll_loss\n",
    "\n",
    "    if gnn_name == 'gin-virtual-bnn':\n",
    "        kl_loss = model.get_kl_loss()[0]\n",
    "        loss += kl_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_accum += loss.detach().cpu().item()\n",
    "    \n",
    "#     break\n",
    "\n",
    "# return loss_accum / (step + 1)\n",
    "loss_accum / (step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7ca08-4069-429f-a2e6-795c52ba8623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b042f16a-a816-4f8b-be62-1f3c2e657459",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-68f371c9e660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ca6ee-9eb7-4fb6-bdc2-e8f33c356674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06169d2-a8d6-40f2-80e5-fd4cf49c2ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "IMPORTANT: GRAPH QUERY ID\n",
    "Pick the graph\n",
    "\"\"\"\n",
    "selectedID = 75088 #0 #131054\n",
    "queryID = split_idx[\"valid\"][selectedID:selectedID + 1]\n",
    "queryID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ceba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0040e",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa15af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = list(valid_loader)[0]\n",
    "data = batch[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbba177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(batch).view(-1,)\n",
    "    \n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ab628",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data.y.item()\n",
    "y_pred = pred.item()\n",
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3b191",
   "metadata": {},
   "source": [
    "## plot sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbf708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(data, y_pred, y_true, ax, printnodelabel=False, printedgelabel=False):\n",
    "\n",
    "    edges = data.edge_index.T.tolist()\n",
    "    edges = np.array(edges)\n",
    "    edges = [(x[0][0], x[0][1], {\"feat\": str(x[1])}) for x in list(zip(edges.tolist(), data.edge_attr.tolist()))]\n",
    "    nodes = [(x[0], {\"feat\": str(x[1])}) for x in enumerate(data.x.tolist())]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    nodelabels = nx.get_node_attributes(G, 'feat') \n",
    "    edgelabels = nx.get_edge_attributes(G, \"feat\")\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    ax.set_title(\"pred={:.2f}, true={:.2f}\".format(y_pred, y_true))\n",
    "    if printnodelabel:\n",
    "        nx.draw(G, pos, labels=nodelabels, ax=ax, node_size=40)\n",
    "    else:\n",
    "        nx.draw(G, pos, ax=ax, node_size=40)\n",
    "        \n",
    "    if printedgelabel:\n",
    "        nx.draw_networkx_edge_labels(G, pos, ax=ax, edge_labels=edgelabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdec21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plotGraph(data, y_pred, y_true, ax, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26beaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a3ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec1b0d78",
   "metadata": {},
   "source": [
    "## perturb edge feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdcb93",
   "metadata": {},
   "source": [
    "edge (5, 6, 2) possible dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e274ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ogb.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeFeatDims = utils.features.get_bond_feature_dims()\n",
    "edgeFeatDims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca868ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_data_list = []\n",
    "\n",
    "for _ in range(5000):\n",
    "    # clone original data\n",
    "    pData = data.clone()\n",
    "    \n",
    "    # create random noise\n",
    "    randomNoise = np.random.randint(low=-4, high=4, size=data.edge_attr.shape)\n",
    "    randomNoise = torch.tensor(randomNoise)\n",
    "\n",
    "    # add edge_attr noise\n",
    "    pData.edge_attr += randomNoise\n",
    "    \n",
    "    pData.edge_attr[:, 0] = pData.edge_attr[:, 0].clip(0, edgeFeatDims[0]-1)\n",
    "    pData.edge_attr[:, 1] = pData.edge_attr[:, 1].clip(0, edgeFeatDims[1]-1)\n",
    "    pData.edge_attr[:, 2] = pData.edge_attr[:, 2].clip(0, edgeFeatDims[2]-1)\n",
    "    \n",
    "    perturb_data_list.append(pData)\n",
    "    \n",
    "len(perturb_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad74ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(perturb_data_list, batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "\n",
    "# get data\n",
    "batch = list(valid_loader)[0]\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(batch) #.view(-1,)\n",
    "    \n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Perturb edge features. Label: {:.2f}\".format(y_true))\n",
    "plt.hist(pred.view(-1).tolist())\n",
    "plt.axvline(y_pred, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35be436",
   "metadata": {},
   "source": [
    "given fixed node features and topology, perturbing edge features don't disturb the output much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6247fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9080eb4",
   "metadata": {},
   "source": [
    "## perturb node features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeDims = utils.features.get_atom_feature_dims()\n",
    "nodeDims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_data_list = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    # clone original data\n",
    "    pData = data.clone()\n",
    "    \n",
    "    # create random noise\n",
    "    randomNoise = np.random.randint(low=-1, high=1, size=data.x.shape)\n",
    "    randomNoise = torch.tensor(randomNoise)\n",
    "\n",
    "    # add edge_attr noise\n",
    "    pData.x += randomNoise\n",
    "    \n",
    "    pData.x[:, 0] = pData.x[:, 0].clip(0, nodeDims[0]-1)\n",
    "    pData.x[:, 1] = pData.x[:, 1].clip(0, nodeDims[1]-1)\n",
    "    pData.x[:, 2] = pData.x[:, 2].clip(0, nodeDims[2]-1)\n",
    "    pData.x[:, 3] = pData.x[:, 2].clip(0, nodeDims[3]-1)\n",
    "    pData.x[:, 4] = pData.x[:, 2].clip(0, nodeDims[4]-1)\n",
    "    pData.x[:, 5] = pData.x[:, 2].clip(0, nodeDims[5]-1)\n",
    "    pData.x[:, 6] = pData.x[:, 2].clip(0, nodeDims[6]-1)\n",
    "    pData.x[:, 7] = pData.x[:, 2].clip(0, nodeDims[7]-1)\n",
    "    pData.x[:, 8] = pData.x[:, 2].clip(0, nodeDims[8]-1)\n",
    "    \n",
    "    perturb_data_list.append(pData)\n",
    "    \n",
    "len(perturb_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9db270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perturb_data_list = [data]\n",
    "\n",
    "# for i in range(1):\n",
    "#     pData = data.clone()\n",
    "# #     pData.x[-1, 0] = torch.tensor(i)\n",
    "#     pData.x[-1] = torch.tensor([ 5,  0,  4,  5,  3,  0,  2,  0,  0])\n",
    "#     perturb_data_list.append(pData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(perturb_data_list, batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "\n",
    "# get data\n",
    "batch = list(valid_loader)[0]\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(batch) #.view(-1,)\n",
    "    \n",
    "pred.shape #, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b006fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Perturb node features. Label: {:.2f}\".format(y_true))\n",
    "plt.hist(pred.view(-1).tolist())\n",
    "plt.axvline(y_pred, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256361a",
   "metadata": {},
   "source": [
    "node features seem very sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bfbf7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b41f4ab",
   "metadata": {},
   "source": [
    "## perturb topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead07825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep backup\n",
    "backup = data.edge_index.clone()\n",
    "backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e0e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perturb_data_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    # clone original data\n",
    "    pData = data.clone()\n",
    "    \n",
    "    # noise parameters\n",
    "    noEdgeSwap = 3\n",
    "\n",
    "    # create edges\n",
    "    edges = pData.edge_index.T.tolist()\n",
    "    edges = np.array(edges)\n",
    "    edges = [(x[0][0], x[0][1], {\"feat\": str(x[1])}) for x in list(zip(edges.tolist(), pData.edge_attr.tolist()))]\n",
    "    nodes = [(x[0], {\"feat\": str(x[1])}) for x in enumerate(pData.x.tolist())]\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # swap edges\n",
    "    G = nx.double_edge_swap(G, noEdgeSwap)\n",
    "    # both directions\n",
    "    newEdges = list(G.edges()) + [(x[1], x[0]) for x in G.edges()]\n",
    "    newEdges = torch.tensor(newEdges).T\n",
    "    # set value\n",
    "    pData.edge_index = newEdges\n",
    "\n",
    "    perturb_data_list.append(pData)\n",
    "    \n",
    "    # visualise some graphs\n",
    "    if i % 50 == 0:\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        nx.draw(G)\n",
    "        plt.show()\n",
    "    \n",
    "len(perturb_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964f64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(perturb_data_list, batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "\n",
    "# get data\n",
    "batch = list(valid_loader)[0]\n",
    "batch = batch.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(batch) #.view(-1,)\n",
    "    \n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Perturb topology. Label: {:.2f}\".format(y_true))\n",
    "plt.hist(pred.view(-1).tolist())\n",
    "plt.axvline(y_pred, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ca069",
   "metadata": {},
   "source": [
    "topology doesn't seem to affect the score too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66794b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f4668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
