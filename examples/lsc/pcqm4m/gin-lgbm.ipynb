{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5dbc3a",
   "metadata": {},
   "source": [
    "ref: https://arxiv.org/pdf/2005.10036.pdf\n",
    "\n",
    "1. run gin to get embedding\n",
    "2. feed embedding to random forest / gp on train\n",
    "3. apply on val and check MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d28e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d482ec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from gnn import GNN\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e90ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from ogb.lsc import PygPCQM4MDataset, PCQM4MEvaluator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b33814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args from main_gnn CLI\n",
    "class Argument(object):\n",
    "    name = \"args\"\n",
    "    \n",
    "args = Argument()\n",
    "args.batch_size = 256\n",
    "args.num_workers = 0\n",
    "args.num_layers = 5\n",
    "args.emb_dim = 600\n",
    "args.drop_ratio = 0\n",
    "args.graph_pooling = \"sum\"\n",
    "args.checkpoint_dir = \"checkpoint\"\n",
    "args.device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533edb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9f2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_params = {\n",
    "    'num_layers': args.num_layers,\n",
    "    'emb_dim': args.emb_dim,\n",
    "    'drop_ratio': args.drop_ratio,\n",
    "    'graph_pooling': args.graph_pooling\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0d520",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b02ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (gnn_node): GNN_node_Virtualnode(\n",
       "    (atom_encoder): AtomEncoder(\n",
       "      (atom_embedding_list): ModuleList(\n",
       "        (0): Embedding(119, 600)\n",
       "        (1): Embedding(4, 600)\n",
       "        (2): Embedding(12, 600)\n",
       "        (3): Embedding(12, 600)\n",
       "        (4): Embedding(10, 600)\n",
       "        (5): Embedding(6, 600)\n",
       "        (6): Embedding(6, 600)\n",
       "        (7): Embedding(2, 600)\n",
       "        (8): Embedding(2, 600)\n",
       "      )\n",
       "    )\n",
       "    (virtualnode_embedding): Embedding(1, 600)\n",
       "    (convs): ModuleList(\n",
       "      (0): GINConv(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "          (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        )\n",
       "        (bond_encoder): BondEncoder(\n",
       "          (bond_embedding_list): ModuleList(\n",
       "            (0): Embedding(5, 600)\n",
       "            (1): Embedding(6, 600)\n",
       "            (2): Embedding(2, 600)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GINConv(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "          (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        )\n",
       "        (bond_encoder): BondEncoder(\n",
       "          (bond_embedding_list): ModuleList(\n",
       "            (0): Embedding(5, 600)\n",
       "            (1): Embedding(6, 600)\n",
       "            (2): Embedding(2, 600)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): GINConv(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "          (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        )\n",
       "        (bond_encoder): BondEncoder(\n",
       "          (bond_embedding_list): ModuleList(\n",
       "            (0): Embedding(5, 600)\n",
       "            (1): Embedding(6, 600)\n",
       "            (2): Embedding(2, 600)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): GINConv(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "          (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        )\n",
       "        (bond_encoder): BondEncoder(\n",
       "          (bond_embedding_list): ModuleList(\n",
       "            (0): Embedding(5, 600)\n",
       "            (1): Embedding(6, 600)\n",
       "            (2): Embedding(2, 600)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): GINConv(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "          (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        )\n",
       "        (bond_encoder): BondEncoder(\n",
       "          (bond_embedding_list): ModuleList(\n",
       "            (0): Embedding(5, 600)\n",
       "            (1): Embedding(6, 600)\n",
       "            (2): Embedding(2, 600)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (mlp_virtualnode_list): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (4): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (4): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (4): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (4): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (graph_pred_linear): Linear(in_features=600, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelName = \"gin-virtual\"\n",
    "gnn_type = \"gin\"\n",
    "virtual_node = True\n",
    "    \n",
    "\"\"\"\n",
    "LOAD Checkpoint data\n",
    "\"\"\"\n",
    "filename = os.path.join(args.checkpoint_dir, \"models\", modelName, \"checkpoint\", 'checkpoint.pt')\n",
    "checkpoint = torch.load(filename)\n",
    "\n",
    "# load model\n",
    "model = GNN(gnn_type = gnn_type, virtual_node = virtual_node, **shared_params).to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29605bc9",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b8e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5e7bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing OGB-LSC\n",
    "from ogb.lsc import PygPCQM4MDataset, PCQM4MEvaluator\n",
    "\n",
    "dataset = PygPCQM4MDataset(root = 'dataset/')\n",
    "split_idx = dataset.get_idx_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e07d8",
   "metadata": {},
   "source": [
    "## test valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Get intermediate graph embeddings and visualise\n",
    "# \"\"\"\n",
    "# def getPred(model):\n",
    "#     valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "    \n",
    "#     y_pred = []\n",
    "#     for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "\n",
    "#         # put batch to cuda\n",
    "#         batch = batch.to(device)\n",
    "\n",
    "#         # collate prediction\n",
    "#         with torch.no_grad():\n",
    "#             pred = model(batch).view(-1,)    \n",
    "#             pred_np = pred.detach().cpu().numpy()\n",
    "#             y_pred.extend(pred_np)\n",
    "\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0888e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|███████████████████████████████████████████████████████████████████| 1487/1487 [00:58<00:00, 25.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# ## collate data as a list\n",
    "\n",
    "# valid_data_list = []\n",
    "# y_true = []\n",
    "# for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "\n",
    "#     # collate data\n",
    "#     for i in range(batch.y.shape[0]):\n",
    "#         valid_data_list.append(batch[i])\n",
    "\n",
    "#     # collate label\n",
    "#     label = batch.y.detach().cpu().numpy()\n",
    "#     y_true.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc98b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get prediction\n",
    "# y_pred = getPred(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b065e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15115168690681458"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # evaluate\n",
    "# evaluator = PCQM4MEvaluator()\n",
    "# input_dict = {\"y_true\": torch.tensor(y_true), \"y_pred\": torch.tensor(y_pred)}\n",
    "# evaluator.eval(input_dict)[\"mae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45306c",
   "metadata": {},
   "source": [
    "## further train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f384cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb831b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphEmbedding(model, batch):\n",
    "    with torch.no_grad():\n",
    "        # get intermediate outputs\n",
    "        h_node = model.gnn_node(batch)\n",
    "        # GRAPH EMBEDDING\n",
    "        h_graph = model.pool(h_node, batch.batch)\n",
    "        # output\n",
    "        output = model.graph_pred_linear(h_graph).view(-1)\n",
    "\n",
    "    return h_graph, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95aa8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████| 11896/11896 [18:46<00:00, 10.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get intermediate graph embeddings and visualise\n",
    "\"\"\"\n",
    "# valid_data_list = []\n",
    "for step, batch in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
    "\n",
    "#     # collate data\n",
    "#     for i in range(batch.y.shape[0]):\n",
    "#         valid_data_list.append(batch[i])\n",
    "\n",
    "    # put batch to cuda\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # get embedding\n",
    "    h_graph, pred = getGraphEmbedding(model, batch)\n",
    "\n",
    "    # collate prediction\n",
    "    pred_np = pred.detach().cpu().numpy()\n",
    "    filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"preds\", \"{}.npy\".format(step))\n",
    "    np.save(filename, pred_np)\n",
    "\n",
    "    # save graph embeddings\n",
    "    h_graph_np = h_graph.detach().cpu().numpy()\n",
    "    filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"embeddings\", \"{}.npy\".format(step))\n",
    "    np.save(filename, h_graph_np)\n",
    "    \n",
    "    # save label\n",
    "    label = batch.y.detach().cpu().numpy()\n",
    "    filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"labels\", \"{}.npy\".format(step))\n",
    "    np.save(filename, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"\")\n",
    "\n",
    "# shutdown the kernel, delete data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad1402",
   "metadata": {},
   "source": [
    "## evaluate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d83a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 11896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f573347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11896/11896 [00:22<00:00, 525.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "load from storage\n",
    "\"\"\"\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for step in tqdm(range(Ntrain)):\n",
    "    filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"preds\", \"{}.npy\".format(step))\n",
    "    pred_np = np.load(filename)\n",
    "    y_pred.extend(pred_np)\n",
    "\n",
    "#     filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"embeddings\", \"{}.npy\".format(step))\n",
    "#     h_graph_np = np.load(filename)\n",
    "#     graphEmbeddings.append(h_graph_np)\n",
    "#     if graphEmbeddings is None:\n",
    "#         graphEmbeddings = h_graph_np\n",
    "#     else:\n",
    "#         graphEmbeddings = np.concatenate((graphEmbeddings, h_graph_np))\n",
    "    \n",
    "    filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"labels\", \"{}.npy\".format(step))\n",
    "    label = np.load(filename)\n",
    "    y_true.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fed0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndata = len(y_true)\n",
    "dim = 600\n",
    "graphEmbeddings = np.zeros((Ndata, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e21963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11896/11896 [00:49<00:00, 240.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# load separately as np.concatenate is too slow\n",
    "for step in tqdm(range(Ntrain)):\n",
    "    filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"embeddings\", \"{}.npy\".format(step))\n",
    "    h_graph_np = np.load(filename)\n",
    "    \n",
    "    minVal = step*256\n",
    "    maxVal = min((step+1)*256, Ndata)\n",
    "    graphEmbeddings[minVal:maxVal, :] = h_graph_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b635845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3045360, 3045360, (3045360, 600))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(y_pred), graphEmbeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be6ffb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10943220555782318"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "evaluator = PCQM4MEvaluator()\n",
    "input_dict = {\"y_true\": torch.tensor(y_true), \"y_pred\": torch.tensor(y_pred)}\n",
    "evaluator.eval(input_dict)[\"mae\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3941e0f",
   "metadata": {},
   "source": [
    "## run pca to reduce dimension of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013a4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA()\n",
    "# pca.fit(graphEmbeddings)\n",
    "\n",
    "# # see what's a good pca threshold\n",
    "# plt.figure(figsize= (10, 5))\n",
    "# plt.xticks(np.arange(0, graphEmbeddings.shape[1], step=10))\n",
    "# plt.plot(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefc5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c7eea15",
   "metadata": {},
   "source": [
    "## predict value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ee15d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe34cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6446e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr = RandomForestRegressor(max_depth=2, random_state=0, criterion=\"mae\")\n",
    "# regr = GradientBoostingRegressor(random_state=1, criterion=\"mae\")\n",
    "# regr = DecisionTreeRegressor(random_state=0)\n",
    "# regr = DecisionTreeRegressor(random_state=0, criterion=\"mae\")\n",
    "\n",
    "regr = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d08b4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling\n",
    "randomIndex = np.random.choice(Ndata, 50000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62fb4381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAIN MODEL\n",
    "\"\"\"\n",
    "\n",
    "regr.fit(graphEmbeddings, y_true)\n",
    "# regr.fit(graphEmbeddings[randomIndex], np.array(y_true)[randomIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04c47edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPred = regr.predict(graphEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3a23bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10800974458228811"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"y_true\": torch.tensor(y_true), \"y_pred\": torch.tensor(rfPred)}\n",
    "evaluator.eval(input_dict)[\"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1e97614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = DotProduct() + WhiteKernel()\n",
    "# gpr = GaussianProcessRegressor(kernel=kernel, random_state=0).fit(graphEmbeddings, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e93894a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gprPred = gpr.predict(graphEmbeddings, return_std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c25723f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict = {\"y_true\": torch.tensor(y_true), \"y_pred\": torch.tensor(gprPred)}\n",
    "# evaluator.eval(input_dict)[\"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "205e3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f204f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"regr\")\n",
    "   \n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(regr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b882bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d77284f9",
   "metadata": {},
   "source": [
    "## evaluate the model on valid\n",
    "\n",
    "1. extract valid embeddings\n",
    "2. feed to regressor\n",
    "3. test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe0860e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = osp.join(\"checkpoint\", \"trainingEmbeddings\", \"regr\")\n",
    "   \n",
    "with open(filename, \"rb\") as f:\n",
    "    regr = pickle.load(f)\n",
    "    \n",
    "regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb2f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce02204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphEmbedding(model, batch):\n",
    "    with torch.no_grad():\n",
    "        # get intermediate outputs\n",
    "        h_node = model.gnn_node(batch)\n",
    "        # GRAPH EMBEDDING\n",
    "        h_graph = model.pool(h_node, batch.batch)\n",
    "        # output\n",
    "        output = model.graph_pred_linear(h_graph).view(-1)\n",
    "\n",
    "    return h_graph, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b23f1826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|███████████████████████████████████████████████████████████████████| 1487/1487 [02:01<00:00, 12.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get intermediate graph embeddings and visualise\n",
    "\"\"\"\n",
    "graphEmbeddingsList = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# valid_data_list = []\n",
    "for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "\n",
    "    # put batch to cuda\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # get embedding\n",
    "    h_graph, pred = getGraphEmbedding(model, batch)\n",
    "\n",
    "    # collate prediction\n",
    "    pred_np = pred.detach().cpu().numpy()\n",
    "    y_pred.extend(pred_np)\n",
    "\n",
    "    # collate graph embedding\n",
    "    h_graph_np = h_graph.detach().cpu().numpy()\n",
    "    graphEmbeddingsList.append(h_graph_np)\n",
    "#     if graphEmbeddings is None:\n",
    "#         graphEmbeddings = h_graph_np\n",
    "#     else:\n",
    "#         graphEmbeddings = np.concatenate((graphEmbeddings, h_graph_np))\n",
    "\n",
    "    # collate label\n",
    "    label = batch.y.detach().cpu().numpy()\n",
    "    y_true.extend(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6430f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndata = len(y_true)\n",
    "dim = 600\n",
    "graphEmbeddings = np.zeros((Ndata, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad13327",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nval = 1487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68effd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1487/1487 [00:00<00:00, 2394.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# load separately as np.concatenate is too slow\n",
    "for step in tqdm(range(Nval)):\n",
    "\n",
    "    h_graph_np = graphEmbeddingsList[step]\n",
    "    \n",
    "    minVal = step*256\n",
    "    maxVal = min((step+1)*256, Ndata)\n",
    "    graphEmbeddings[minVal:maxVal, :] = h_graph_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e729789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPred = regr.predict(graphEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac64dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = PCQM4MEvaluator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba05f1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15115167200565338"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"y_true\": torch.tensor(y_true), \"y_pred\": torch.tensor(y_pred)}\n",
    "evaluator.eval(input_dict)[\"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46dc7acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1507685979572607"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"y_true\": torch.tensor(y_true), \"y_pred\": torch.tensor(rfPred)}\n",
    "evaluator.eval(input_dict)[\"mae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9318cc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23af8c66648>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d4337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5f67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285de382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b55ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68357df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4ed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01920e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e6925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
